{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e75a0ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in ./craig/lib/python3.13/site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy in ./craig/lib/python3.13/site-packages (2.2.6)\n",
      "Requirement already satisfied: tensorflow in ./craig/lib/python3.13/site-packages (2.20.0)\n",
      "Requirement already satisfied: scikit-learn in ./craig/lib/python3.13/site-packages (1.7.1)\n",
      "Requirement already satisfied: soundfile in ./craig/lib/python3.13/site-packages (0.13.1)\n",
      "Requirement already satisfied: tf2onnx in ./craig/lib/python3.13/site-packages (1.8.4)\n",
      "Requirement already satisfied: joblib in ./craig/lib/python3.13/site-packages (1.5.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./craig/lib/python3.13/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in ./craig/lib/python3.13/site-packages (from librosa) (0.61.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./craig/lib/python3.13/site-packages (from librosa) (1.16.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./craig/lib/python3.13/site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: pooch>=1.1 in ./craig/lib/python3.13/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./craig/lib/python3.13/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in ./craig/lib/python3.13/site-packages (from librosa) (4.14.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in ./craig/lib/python3.13/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in ./craig/lib/python3.13/site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: standard-aifc in ./craig/lib/python3.13/site-packages (from librosa) (3.13.0)\n",
      "Requirement already satisfied: standard-sunau in ./craig/lib/python3.13/site-packages (from librosa) (3.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./craig/lib/python3.13/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./craig/lib/python3.13/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./craig/lib/python3.13/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./craig/lib/python3.13/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in ./craig/lib/python3.13/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./craig/lib/python3.13/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in ./craig/lib/python3.13/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./craig/lib/python3.13/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in ./craig/lib/python3.13/site-packages (from tensorflow) (6.32.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./craig/lib/python3.13/site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in ./craig/lib/python3.13/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./craig/lib/python3.13/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./craig/lib/python3.13/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./craig/lib/python3.13/site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./craig/lib/python3.13/site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in ./craig/lib/python3.13/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in ./craig/lib/python3.13/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./craig/lib/python3.13/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in ./craig/lib/python3.13/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./craig/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./craig/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./craig/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./craig/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./craig/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: pillow in ./craig/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./craig/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./craig/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./craig/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in ./craig/lib/python3.13/site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: onnx>=1.4.1 in ./craig/lib/python3.13/site-packages (from tf2onnx) (1.19.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./craig/lib/python3.13/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: pycparser in ./craig/lib/python3.13/site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: rich in ./craig/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in ./craig/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in ./craig/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in ./craig/lib/python3.13/site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./craig/lib/python3.13/site-packages (from pooch>=1.1->librosa) (4.3.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./craig/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./craig/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./craig/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./craig/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: standard-chunk in ./craig/lib/python3.13/site-packages (from standard-aifc->librosa) (3.13.0)\n",
      "Requirement already satisfied: audioop-lts in ./craig/lib/python3.13/site-packages (from standard-aifc->librosa) (0.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install librosa numpy tensorflow scikit-learn soundfile tf2onnx joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8ba5a7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ck/z90f92f10yv212gw46c7jgvc0000gn/T/ipykernel_2331/4257240248.py:13: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio_waveform, sample_rate = librosa.load( # load the waveform representation of the audio file\n",
      "/Users/lukegriggs/Desktop/Side-Projects/craig/craig/lib/python3.13/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "# DATA\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "craig_dir = \"wake_word_samples/craig\"\n",
    "not_craig_dir = \"wake_word_samples/not-craig\"\n",
    "\n",
    "\n",
    "def getInputVector(filePath: str):\n",
    "\n",
    "    audio_waveform, sample_rate = librosa.load( # load the waveform representation of the audio file\n",
    "        filePath,\n",
    "        sr=16000,\n",
    "    )\n",
    "\n",
    "    mfcc_features = librosa.feature.mfcc( # extract the 13 coefficients (this is a 13 x t matrix where t = num of time frames in the sample)\n",
    "        y=audio_waveform,\n",
    "        sr=sample_rate,\n",
    "        n_mfcc=13,\n",
    "        n_fft=512,\n",
    "        hop_length=160\n",
    "    )\n",
    "\n",
    "    feature_vector = np.concatenate([\n",
    "        np.mean(mfcc_features, axis=1),   # Average each coefficient over time\n",
    "        np.std(mfcc_features, axis=1),    # Standard deviation over time\n",
    "        np.max(mfcc_features, axis=1),    # Maximum value over time\n",
    "        np.min(mfcc_features, axis=1)     # Minimum value over time\n",
    "    ])\n",
    "\n",
    "    return feature_vector\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "for filename in os.listdir(craig_dir):\n",
    "    filePath = craig_dir + \"/\" + filename\n",
    "    X.append(getInputVector(filePath))\n",
    "    y.append(1) # 1 for wake word detected   \n",
    "\n",
    "for filename in os.listdir(not_craig_dir):\n",
    "    filePath = not_craig_dir + \"/\" + filename\n",
    "    X.append(getInputVector(filePath))\n",
    "    y.append(0) # 0 for wake word not detected    \n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "37e05676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, shuffle=True, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0f6da097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural net \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],), name='mfcc_input'),\n",
    "\n",
    "    # hidden layer 1\n",
    "    tf.keras.layers.Dense(256, activation='relu', name='hidden1'),\n",
    "    tf.keras.layers.Dropout(0.3, name='dropout1'),\n",
    "\n",
    "    tf.keras.layers.Dense(128, activation='relu', name='hidden4'),\n",
    "    tf.keras.layers.Dropout(0.3, name='dropout4'),\n",
    "\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', name='output')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2b5c8285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 492ms/step - accuracy: 0.4375 - loss: 64.9354 - precision: 0.4000 - recall: 1.0000\n",
      "Epoch 1: val_accuracy improved from None to 0.68000, saving model to craig_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6325 - loss: 25.5948 - precision: 0.3790 - recall: 0.4017 - val_accuracy: 0.6800 - val_loss: 3.6475 - val_precision: 1.0000 - val_recall: 0.0303 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5000 - loss: 23.7797 - precision: 0.2222 - recall: 0.6667\n",
      "Epoch 2: val_accuracy did not improve from 0.68000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6125 - loss: 18.1944 - precision: 0.3273 - recall: 0.3077 - val_accuracy: 0.3500 - val_loss: 11.6868 - val_precision: 0.3367 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 2.4173 - precision: 0.7143 - recall: 0.8333\n",
      "Epoch 3: val_accuracy improved from 0.68000 to 0.71000, saving model to craig_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6400 - loss: 11.0114 - precision: 0.3846 - recall: 0.3846 - val_accuracy: 0.7100 - val_loss: 1.2909 - val_precision: 0.7000 - val_recall: 0.2121 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6250 - loss: 12.2642 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 4: val_accuracy improved from 0.71000 to 0.78000, saving model to craig_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6400 - loss: 6.6167 - precision: 0.3866 - recall: 0.3932 - val_accuracy: 0.7800 - val_loss: 0.8009 - val_precision: 0.7895 - val_recall: 0.4545 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 1.5586 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 5: val_accuracy improved from 0.78000 to 0.83000, saving model to craig_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6775 - loss: 4.4006 - precision: 0.4483 - recall: 0.4444 - val_accuracy: 0.8300 - val_loss: 0.4684 - val_precision: 0.8333 - val_recall: 0.6061 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6875 - loss: 4.5424 - precision: 0.6250 - recall: 0.7143\n",
      "Epoch 6: val_accuracy did not improve from 0.83000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7025 - loss: 3.0299 - precision: 0.4914 - recall: 0.4872 - val_accuracy: 0.7700 - val_loss: 0.4281 - val_precision: 0.6923 - val_recall: 0.5455 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6250 - loss: 3.2822 - precision: 0.3333 - recall: 1.0000\n",
      "Epoch 7: val_accuracy did not improve from 0.83000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6900 - loss: 2.4527 - precision: 0.4679 - recall: 0.4359 - val_accuracy: 0.8200 - val_loss: 0.4253 - val_precision: 0.7778 - val_recall: 0.6364 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7500 - loss: 1.6440 - precision: 0.8333 - recall: 0.6250\n",
      "Epoch 8: val_accuracy did not improve from 0.83000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6800 - loss: 1.7197 - precision: 0.4530 - recall: 0.4530 - val_accuracy: 0.6600 - val_loss: 0.4609 - val_precision: 0.3333 - val_recall: 0.0303 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7500 - loss: 0.8506 - precision: 0.5000 - recall: 0.2500\n",
      "Epoch 9: val_accuracy did not improve from 0.83000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6900 - loss: 1.5018 - precision: 0.4660 - recall: 0.4103 - val_accuracy: 0.7900 - val_loss: 0.5921 - val_precision: 0.6154 - val_recall: 0.9697 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5625 - loss: 1.7863 - precision: 0.6667 - recall: 0.2500\n",
      "Epoch 10: val_accuracy did not improve from 0.83000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7025 - loss: 1.0919 - precision: 0.4912 - recall: 0.4786 - val_accuracy: 0.6700 - val_loss: 0.5931 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6250 - loss: 2.0197 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 11: val_accuracy did not improve from 0.83000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6425 - loss: 0.9541 - precision: 0.3818 - recall: 0.3590 - val_accuracy: 0.6700 - val_loss: 0.6210 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6875 - loss: 0.7798 - precision: 0.2500 - recall: 0.3333\n",
      "Epoch 12: val_accuracy did not improve from 0.83000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7300 - loss: 0.7821 - precision: 0.5692 - recall: 0.3162 - val_accuracy: 0.6700 - val_loss: 0.6274 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6875 - loss: 0.9755 - precision: 0.6667 - recall: 0.3333\n",
      "Epoch 13: val_accuracy did not improve from 0.83000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6700 - loss: 0.7740 - precision: 0.4157 - recall: 0.3162 - val_accuracy: 0.6900 - val_loss: 0.6483 - val_precision: 0.7500 - val_recall: 0.0909 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8750 - loss: 0.2737 - precision: 0.6667 - recall: 0.6667\n",
      "Epoch 14: val_accuracy did not improve from 0.83000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7275 - loss: 0.6060 - precision: 0.5444 - recall: 0.4188 - val_accuracy: 0.7300 - val_loss: 0.5977 - val_precision: 0.8000 - val_recall: 0.2424 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7500 - loss: 0.6369 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 0.83000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7050 - loss: 0.6594 - precision: 0.4940 - recall: 0.3504 - val_accuracy: 0.7500 - val_loss: 0.5425 - val_precision: 0.8333 - val_recall: 0.3030 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8750 - loss: 0.3930 - precision: 0.7500 - recall: 0.7500\n",
      "Epoch 16: val_accuracy did not improve from 0.83000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6975 - loss: 0.6738 - precision: 0.4787 - recall: 0.3846 - val_accuracy: 0.7100 - val_loss: 0.5259 - val_precision: 0.8333 - val_recall: 0.1515 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7500 - loss: 0.5442 - precision: 0.5000 - recall: 0.5000\n",
      "Epoch 17: val_accuracy improved from 0.83000 to 0.89000, saving model to craig_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7350 - loss: 0.6207 - precision: 0.5618 - recall: 0.4274 - val_accuracy: 0.8900 - val_loss: 0.5141 - val_precision: 0.8235 - val_recall: 0.8485 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6875 - loss: 0.3711 - precision: 0.4000 - recall: 0.5000\n",
      "Epoch 18: val_accuracy did not improve from 0.89000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7075 - loss: 0.6070 - precision: 0.5000 - recall: 0.4701 - val_accuracy: 0.7100 - val_loss: 0.5087 - val_precision: 0.7000 - val_recall: 0.2121 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6875 - loss: 0.6418 - precision: 1.0000 - recall: 0.2857\n",
      "Epoch 19: val_accuracy did not improve from 0.89000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7300 - loss: 0.5574 - precision: 0.5584 - recall: 0.3675 - val_accuracy: 0.7100 - val_loss: 0.5052 - val_precision: 0.7500 - val_recall: 0.1818 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6250 - loss: 1.0403 - precision: 1.0000 - recall: 0.1429\n",
      "Epoch 20: val_accuracy did not improve from 0.89000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7150 - loss: 0.6297 - precision: 0.5176 - recall: 0.3761 - val_accuracy: 0.8600 - val_loss: 0.5029 - val_precision: 0.8519 - val_recall: 0.6970 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6875 - loss: 0.5763 - precision: 0.2500 - recall: 0.3333\n",
      "Epoch 21: val_accuracy did not improve from 0.89000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7225 - loss: 0.5880 - precision: 0.5319 - recall: 0.4274 - val_accuracy: 0.8400 - val_loss: 0.5354 - val_precision: 0.8400 - val_recall: 0.6364 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9375 - loss: 0.3998 - precision: 1.0000 - recall: 0.8000\n",
      "Epoch 22: val_accuracy did not improve from 0.89000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7725 - loss: 0.5197 - precision: 0.6354 - recall: 0.5214 - val_accuracy: 0.8500 - val_loss: 0.4930 - val_precision: 0.8000 - val_recall: 0.7273 - learning_rate: 5.0000e-04\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,  # Stop if no improvement for 15 epochs\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.5,  # Reduce learning rate by half\n",
    "        patience=8,  # After 8 epochs of no improvement\n",
    "        verbose=1,\n",
    "        min_lr=1e-6\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        'craig_best.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "        \n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,  # Maximum epochs\n",
    "    batch_size=16,  # Small batches for small dataset\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "665f4408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Craig       0.84      0.91      0.87        67\n",
      "       Craig       0.78      0.64      0.70        33\n",
      "\n",
      "    accuracy                           0.82       100\n",
      "   macro avg       0.81      0.77      0.79       100\n",
      "weighted avg       0.82      0.82      0.81       100\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[61  6]\n",
      " [12 21]]\n",
      "\n",
      "Detailed Results:\n",
      "True Positives (Craig correctly detected): 21\n",
      "False Positives (false Craig alarms): 6\n",
      "True Negatives (non-Craig correctly rejected): 61\n",
      "False Negatives (Craig missed): 12\n",
      "\n",
      "Performance Metrics:\n",
      "Precision: 0.778 (when model says 'Craig', how often is it right?)\n",
      "Recall: 0.636 (of all actual 'Craig' samples, how many did we catch?)\n",
      "F1-Score: 0.700 (balance between precision and recall)\n",
      "\n",
      "Threshold Analysis:\n",
      "  Threshold 0.3: Accuracy=0.810, False Positives=46.000, Missed Detections=54.000\n",
      "  Threshold 0.4: Accuracy=0.830, False Positives=36.000, Missed Detections=64.000\n",
      "  Threshold 0.5: Accuracy=0.820, False Positives=27.000, Missed Detections=73.000\n",
      "  Threshold 0.6: Accuracy=0.790, False Positives=20.000, Missed Detections=80.000\n",
      "  Threshold 0.7: Accuracy=0.750, False Positives=14.000, Missed Detections=86.000\n",
      "  Threshold 0.8: Accuracy=0.710, False Positives=10.000, Missed Detections=90.000\n"
     ]
    }
   ],
   "source": [
    "# evals\n",
    "\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Not Craig', 'Craig']))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Detailed breakdown\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nDetailed Results:\")\n",
    "print(f\"True Positives (Craig correctly detected): {tp}\")\n",
    "print(f\"False Positives (false Craig alarms): {fp}\")\n",
    "print(f\"True Negatives (non-Craig correctly rejected): {tn}\")\n",
    "print(f\"False Negatives (Craig missed): {fn}\")\n",
    "\n",
    "# Performance metrics\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"\\nPerformance Metrics:\")\n",
    "print(f\"Precision: {precision:.3f} (when model says 'Craig', how often is it right?)\")\n",
    "print(f\"Recall: {recall:.3f} (of all actual 'Craig' samples, how many did we catch?)\")\n",
    "print(f\"F1-Score: {f1:.3f} (balance between precision and recall)\")\n",
    "\n",
    "# Threshold analysis\n",
    "print(f\"\\nThreshold Analysis:\")\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "for threshold in thresholds:\n",
    "    y_pred_thresh = (y_pred_prob > threshold).astype(int)\n",
    "    accuracy = np.mean(y_pred_thresh.flatten() == y_test)\n",
    "    \n",
    "    # False positive rate (false alarms)\n",
    "    fp_rate = np.sum((y_pred_thresh == 1) & (y_test == 0)) / np.sum(y_test == 0)\n",
    "    # False negative rate (missed detections)  \n",
    "    fn_rate = np.sum((y_pred_thresh == 0) & (y_test == 1)) / np.sum(y_test == 1)\n",
    "    \n",
    "    print(f\"  Threshold {threshold}: Accuracy={accuracy:.3f}, \"\n",
    "            f\"False Positives={fp_rate:.3f}, Missed Detections={fn_rate:.3f}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9a3bb4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved\n",
      "Keras model saved\n",
      "INFO:tensorflow:Assets written to: /var/folders/ck/z90f92f10yv212gw46c7jgvc0000gn/T/tmp5d25ld0y/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/ck/z90f92f10yv212gw46c7jgvc0000gn/T/tmp5d25ld0y/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/ck/z90f92f10yv212gw46c7jgvc0000gn/T/tmp5d25ld0y'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 52), dtype=tf.float32, name='mfcc_input')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  12960892304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  12960893648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13009932304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13009941328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13009931152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13009940752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1756355961.196157   14340 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1756355961.196167   14340 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Lite model saved: craig.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 23:39:21.196428: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/ck/z90f92f10yv212gw46c7jgvc0000gn/T/tmp5d25ld0y\n",
      "2025-08-27 23:39:21.196702: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-08-27 23:39:21.196706: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/ck/z90f92f10yv212gw46c7jgvc0000gn/T/tmp5d25ld0y\n",
      "2025-08-27 23:39:21.198953: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-08-27 23:39:21.212221: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/ck/z90f92f10yv212gw46c7jgvc0000gn/T/tmp5d25ld0y\n",
      "2025-08-27 23:39:21.215813: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 19385 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "\n",
    "# Save scaler\n",
    "scaler_path = \"craig_scaler.pkl\"\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(\"Scaler saved\")\n",
    "\n",
    "# Save Keras model\n",
    "keras_path = \"craig_keras.h5\"\n",
    "model.save(keras_path)\n",
    "print(\"Keras model saved\")\n",
    "\n",
    "# Convert to TensorFlow Lite (better than ONNX for this use case)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save TFLite model\n",
    "tflite_path = \"craig.tflite\"\n",
    "with open(tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TensorFlow Lite model saved: {tflite_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218c03d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "craig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
